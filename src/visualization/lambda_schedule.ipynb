{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d3b64aa2",
   "metadata": {},
   "source": [
    "# Lambda Schedule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f903d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26016c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "result_dir = Path(\"../../results/wandbs\")\n",
    "result_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11eb3b7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve metrics from summary json dict for each run in a project\n",
    "\n",
    "from typing import Any\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "api = wandb.Api()\n",
    "\n",
    "ENTITY = \"your-wandb-entity\"  # Replace with your W&B username or team name\n",
    "PROJECT = \"position-bias\"\n",
    "\n",
    "project_path = f\"{ENTITY}/{PROJECT}\"\n",
    "\n",
    "print(f\"Fetching runs from project: {project_path}\")\n",
    "runs = api.runs(path=project_path)\n",
    "\n",
    "metrics_list = []\n",
    "\n",
    "for run_ind, run in enumerate(runs):\n",
    "    print(f\"Processing run {run_ind}: {run.id}\")\n",
    "    if run.state == \"finished\":\n",
    "        print(f\"Run {run.id} is finished.\")\n",
    "    else:\n",
    "        print(f\"Run {run.id} is not finished. Skipping.\")\n",
    "        continue\n",
    "\n",
    "    print(\"Fetching metrics...\")\n",
    "    metrics_names = [\n",
    "        \"final/attn_mean\",\n",
    "        \"final/attn_stddev\",\n",
    "        \"final/res_mean\",\n",
    "        \"final/res_stddev\",\n",
    "        \"final/layer_idx\",\n",
    "    ]\n",
    "    metrics_df = run.history(keys=metrics_names, x_axis=\"final/layer_idx\", pandas=True)\n",
    "    metrics_df = metrics_df.rename(columns=lambda x: x.replace(\"final/\", \"\"))\n",
    "\n",
    "    metrics_df[\"run_id\"] = run.id\n",
    "    metrics_df[\"run_name\"] = run.name\n",
    "\n",
    "    def unfold_dict(\n",
    "        dictionary: dict[str, Any],\n",
    "        parent_key: str = \"\",\n",
    "        sep: str = \"_\",\n",
    "    ) -> dict[str, Any]:\n",
    "        \"\"\"Unfold nested dictionary into a flat dictionary.\"\"\"\n",
    "        items = {}\n",
    "        for key, value in dictionary.items():\n",
    "            new_key = f\"{parent_key}{sep}{key}\" if parent_key else key\n",
    "            if isinstance(value, (str, int, bool, float)):\n",
    "                items[new_key] = value\n",
    "            elif isinstance(value, list):\n",
    "                if len(value) == 1:\n",
    "                    items[new_key] = value[0]\n",
    "                else:\n",
    "                    items[new_key] = np.nan\n",
    "            elif isinstance(value, dict):\n",
    "                items.update(unfold_dict(value, new_key))\n",
    "            elif value is None:\n",
    "                items[new_key] = np.nan\n",
    "            else:\n",
    "                raise ValueError(f\"Unsupported type: {type(value)}\")\n",
    "        return items\n",
    "\n",
    "    run_config = unfold_dict(run.config)\n",
    "    for key, value in run_config.items():\n",
    "        metrics_df[key] = value\n",
    "\n",
    "    metrics_list.append(metrics_df)\n",
    "    print(f\"Successfully retrieved metrics for run {run.id}.\")\n",
    "\n",
    "combined_metrics = pd.concat(metrics_list, ignore_index=True)\n",
    "print(\"Successfully combined all metrics into a single DataFrame.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07e69f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_metrics.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019bf718",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(combined_metrics.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b3b2c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_metrics[\"hf_model_config_model_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e8aa84",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df = combined_metrics[\n",
    "    [\n",
    "        \"run_id\",\n",
    "        \"dataset_config_repo_id\",\n",
    "        \"hf_model_config_model_id\",\n",
    "        \"num_batches\",\n",
    "        \"batch_size\",\n",
    "        \"sequence_length\",\n",
    "        \"attn_mean\",\n",
    "        \"attn_stddev\",\n",
    "        \"res_mean\",\n",
    "        \"res_stddev\",\n",
    "        \"layer_idx\",\n",
    "    ]\n",
    "]\n",
    "clean_df.loc[:, \"hf_model_config_model_id\"] = (\n",
    "    clean_df[\"hf_model_config_model_id\"].str.split(\"/\").str[-1].str.lower()\n",
    ")\n",
    "# rename some models for consistency\n",
    "clean_df.loc[\n",
    "    clean_df[\"hf_model_config_model_id\"] == \"bloom-7b1\",\n",
    "    \"hf_model_config_model_id\",\n",
    "] = \"bloom-7b\"\n",
    "clean_df.loc[\n",
    "    clean_df[\"hf_model_config_model_id\"] == \"bloom\",\n",
    "    \"hf_model_config_model_id\",\n",
    "] = \"bloom-176b\"\n",
    "clean_df.loc[\n",
    "    clean_df[\"hf_model_config_model_id\"] == \"mpt-30b-peft-compatible\",\n",
    "    \"hf_model_config_model_id\",\n",
    "] = \"mpt-30b\"\n",
    "clean_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48b9f4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df[\"hf_model_config_model_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8e66548",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.axes import Axes\n",
    "from matplotlib.figure import Figure\n",
    "import matplotlib.pyplot as plt\n",
    "import scienceplots  # noqa: F401\n",
    "\n",
    "\n",
    "def style_attn_plot(ax: Axes) -> None:\n",
    "    \"\"\"Style attention plot axes.\"\"\"\n",
    "    plt.style.use([\"science\", \"bright\", \"grid\", \"no-latex\"])\n",
    "    # Use sans-serif fonts (incl. mathtext) for cleaner small-scale rendering.\n",
    "    plt.rcParams.update(\n",
    "        {\n",
    "            \"font.family\": \"sans-serif\",\n",
    "            \"font.sans-serif\": [\"DejaVu Sans\", \"Liberation Sans\", \"Arial\"],\n",
    "            \"mathtext.fontset\": \"dejavusans\",\n",
    "        },\n",
    "    )\n",
    "    ax.set_xlabel(\"Layer\", fontsize=10)\n",
    "    ax.set_ylabel(ylabel, fontsize=10)\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=9)\n",
    "    ax.set_ylim(0, 1)\n",
    "    ax.legend(fontsize=9, frameon=False, handlelength=1.2, columnspacing=0.8)\n",
    "    ax.margins(x=0.02)\n",
    "    ax.grid(visible=True, which=\"major\", alpha=0.2)\n",
    "\n",
    "\n",
    "def plot_attn_mean_by_layer(\n",
    "    clean_df: pd.DataFrame,\n",
    "    selected_models: list[str],\n",
    "    dataset_name: str = \"HuggingFaceFW/fineweb-edu\",\n",
    "    sequence_length: int = 2048,\n",
    ") -> tuple[Figure, Axes, pd.DataFrame]:\n",
    "    \"\"\"Plot attention mean by layer for selected models.\"\"\"\n",
    "    selected_models = [m.split(\"/\")[-1].lower() for m in selected_models]\n",
    "    plot_df = clean_df[\n",
    "        clean_df[\"hf_model_config_model_id\"].isin(selected_models)\n",
    "    ].copy()\n",
    "    plot_df = plot_df[plot_df[\"sequence_length\"] == sequence_length]\n",
    "    plot_df = plot_df[plot_df[\"dataset_config_repo_id\"] == dataset_name]\n",
    "    plot_df = plot_df.sort_values([\"hf_model_config_model_id\", \"layer_idx\"])\n",
    "    # lower case hf_model_config_model_id for consistency\n",
    "    plot_df[\"hf_model_config_model_id\"] = plot_df[\n",
    "        \"hf_model_config_model_id\"\n",
    "    ].str.lower()\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(4.5, 2), dpi=400)\n",
    "\n",
    "    grouped = plot_df.groupby(\"hf_model_config_model_id\", sort=False)\n",
    "    for model_id in selected_models:\n",
    "        if model_id in grouped.groups:\n",
    "            group = grouped.get_group(model_id)\n",
    "            x = group[\"layer_idx\"].to_numpy()\n",
    "            y = group[\"attn_mean\"].to_numpy()\n",
    "            ci = (2 * group[\"attn_stddev\"]).to_numpy()\n",
    "\n",
    "            ax.plot(x, y, label=model_id, linewidth=1.5)\n",
    "            ax.fill_between(\n",
    "                x,\n",
    "                y - ci,\n",
    "                y + ci,\n",
    "                alpha=0.2,\n",
    "                linewidth=0,\n",
    "            )\n",
    "\n",
    "    style_attn_plot(ax)\n",
    "    fig.tight_layout()\n",
    "    return fig, ax, plot_df\n",
    "\n",
    "\n",
    "def save_figure(fig: Figure, filename: str) -> None:\n",
    "    \"\"\"Save figure to paper folder as PDF.\"\"\"\n",
    "    fig.savefig(\n",
    "        result_dir / filename,\n",
    "        format=\"pdf\",\n",
    "        dpi=400,\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    print(f\"Figure saved to {result_dir / filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47864b57",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_df[\"dataset_config_repo_id\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa241390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a few models for the plot (edit this list as needed).\n",
    "selected_models = [\n",
    "    \"falcon-rw-7b\",\n",
    "    \"mpt-7b\",\n",
    "    \"mpt-30b\",\n",
    "    \"bloom-7b\",\n",
    "    \"bloom-176b\",\n",
    "]\n",
    "\n",
    "# dataset_name = \"HuggingFaceFW/fineweb-edu\"\n",
    "# dataset_name = \"mlfoundations/dclm-baseline-1.0\"\n",
    "dataset_name = \"wikimedia/wikipedia\"\n",
    "\n",
    "sequence_length = 512\n",
    "\n",
    "fig, ax, plot_df = plot_attn_mean_by_layer(\n",
    "    clean_df,\n",
    "    selected_models,\n",
    "    dataset_name=dataset_name,\n",
    "    sequence_length=sequence_length,\n",
    ")\n",
    "display(plot_df)\n",
    "plt.show()\n",
    "\n",
    "figure_name = f\"lambda_t_alibi_{dataset_name.replace('/', '_')}_{sequence_length}.pdf\"\n",
    "save_figure(fig, figure_name)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "position-bias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
