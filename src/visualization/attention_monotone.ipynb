{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "73f129fd",
   "metadata": {},
   "source": [
    "# Attention Monotone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb58323f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "import einops\n",
    "from jaxtyping import Float\n",
    "from matplotlib.axes import Axes\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scienceplots  # noqa: F401\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "216de37e",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"/data/shared_data/position-bias/results-final-fineweb-edu\"\n",
    "model_names = [\n",
    "    \"anas-awadalla_mpt-7b\",\n",
    "    \"bigscience_bloom\",\n",
    "    \"bigscience_bloom-7b1\",\n",
    "    \"tiiuae_falcon-rw-7b\",\n",
    "    \"eluzhnica_mpt-30b-peft-compatible\",\n",
    "]\n",
    "\n",
    "sequence_length = 256\n",
    "show_std_error = False\n",
    "\n",
    "result_dir = Path(\"../../results/monotonicity\")\n",
    "result_dir.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b3e55e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class LayerStats:\n",
    "    \"\"\"Statistics for a single layer.\"\"\"\n",
    "\n",
    "    combinations: int = 0\n",
    "    violations_count: int = 0\n",
    "    total_absolute_error: float = 0.0\n",
    "    total_relative_error: float = 0.0\n",
    "\n",
    "    violation_rate: float = 0.0\n",
    "    absolute_error: float = 0.0\n",
    "    absolute_error_std: float = 0.0\n",
    "    relative_error: float = 0.0\n",
    "    relative_error_std: float = 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db747378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_alibi_slopes(\n",
    "    n_heads: int,\n",
    ") -> Float[torch.Tensor, \"n_heads\"]:\n",
    "    \"\"\"Compute the ALiBi slopes for each attention head.\"\"\"\n",
    "    return torch.tensor(\n",
    "        [pow(2, -8 * (h + 1) / n_heads) for h in range(n_heads)],\n",
    "        dtype=torch.float64,\n",
    "    )\n",
    "\n",
    "\n",
    "def compute_alibi_scores(\n",
    "    n_layers: int,\n",
    "    n_heads: int,\n",
    ") -> Float[torch.Tensor, \"n_layers n_heads sequence_length sequence_length\"]:\n",
    "    \"\"\"Compute the positional-only ALiBi scores.\"\"\"\n",
    "    head_alphas = einops.rearrange(compute_alibi_slopes(n_heads), \"h -> h 1 1\")\n",
    "\n",
    "    i = einops.rearrange(\n",
    "        torch.arange(sequence_length, dtype=torch.float64),\n",
    "        \"n -> n 1\",\n",
    "    )\n",
    "    j = einops.rearrange(\n",
    "        torch.arange(sequence_length, dtype=torch.float64),\n",
    "        \"n -> 1 n\",\n",
    "    )\n",
    "    distances = i - j\n",
    "\n",
    "    scores = -head_alphas * distances\n",
    "\n",
    "    return einops.repeat(scores, \"h i j -> l h i j\", l=n_layers)\n",
    "\n",
    "\n",
    "def load_attention_matrix(\n",
    "    model_name: str,\n",
    ") -> Float[torch.Tensor, \"n_layers n_heads seq_len seq_len\"]:\n",
    "    \"\"\"Load the mean attention matrix for a given model.\"\"\"\n",
    "    result_dir = Path(data_path) / model_name / str(sequence_length)\n",
    "    mean_attention_matrix: Float[torch.Tensor, \"n_layers n_heads seq_len seq_len\"] = (\n",
    "        torch.load(result_dir / \"attention_probs_mean.pt\").to(torch.float64)\n",
    "    )\n",
    "\n",
    "    n_layers, n_heads, _, _ = mean_attention_matrix.shape\n",
    "\n",
    "    mean_attention_matrix += compute_alibi_scores(\n",
    "        n_layers=n_layers,\n",
    "        n_heads=n_heads,\n",
    "    )\n",
    "\n",
    "    return mean_attention_matrix\n",
    "\n",
    "\n",
    "def compute_softmax_attention(\n",
    "    attention_matrix: Float[torch.Tensor, \"n_layers n_heads seq_len seq_len\"],\n",
    ") -> Float[torch.Tensor, \"n_layers seq_len seq_len\"]:\n",
    "    \"\"\"Apply causal masking and softmax to the attention matrix.\"\"\"\n",
    "    masked_attention_matrix = attention_matrix.masked_fill(\n",
    "        ~torch.ones_like(attention_matrix, dtype=torch.bool).tril(),\n",
    "        float(\"-inf\"),\n",
    "    )\n",
    "    softmax_attention_matrix = torch.nn.functional.softmax(\n",
    "        masked_attention_matrix,\n",
    "        dim=-1,\n",
    "    )\n",
    "\n",
    "    # We only need monotonicity to hold in expectation across heads\n",
    "    softmax_attention_matrix = einops.reduce(\n",
    "        softmax_attention_matrix,\n",
    "        \"l h i j -> l i j\",\n",
    "        \"mean\",\n",
    "    )\n",
    "\n",
    "    return softmax_attention_matrix\n",
    "\n",
    "\n",
    "def compute_monotonicity_stats(\n",
    "    attention_matrix: Float[torch.Tensor, \"n_layers seq_len seq_len\"],\n",
    ") -> list[LayerStats]:\n",
    "    \"\"\"Compute monotonicity violation statistics for each layer.\"\"\"\n",
    "    n_layers, seq_len, _ = attention_matrix.shape\n",
    "\n",
    "    cumsum: Float[torch.Tensor, \"n_layers seq_len seq_len\"] = attention_matrix.cumsum(\n",
    "        dim=-1,\n",
    "    )\n",
    "\n",
    "    all_layer_stats: list[LayerStats] = []\n",
    "\n",
    "    i_indices, j_indices = torch.triu_indices(\n",
    "        seq_len,\n",
    "        seq_len,\n",
    "        offset=1,\n",
    "        device=attention_matrix.device,\n",
    "    )\n",
    "    num_pairs = i_indices.shape[0]\n",
    "    total_combinations = num_pairs * seq_len\n",
    "\n",
    "    epsilon = 1e-10\n",
    "\n",
    "    for layer_idx in range(n_layers):\n",
    "        layer_i = cumsum[layer_idx, i_indices]\n",
    "        layer_j = cumsum[layer_idx, j_indices]\n",
    "\n",
    "        diff = layer_i - layer_j\n",
    "        violating_positions = diff < -epsilon\n",
    "        violations_count = int(violating_positions.sum().item())\n",
    "\n",
    "        total_absolute_error = 0.0\n",
    "        total_relative_error = 0.0\n",
    "        absolute_error_std = 0.0\n",
    "        relative_error_std = 0.0\n",
    "\n",
    "        if violations_count > 0:\n",
    "            violating_diff = diff[violating_positions]\n",
    "            absolute_errors = violating_diff.abs()\n",
    "            total_absolute_error = absolute_errors.sum().item()\n",
    "            if violations_count > 1:\n",
    "                absolute_error_std = absolute_errors.std().item()\n",
    "\n",
    "            val_i = layer_i[violating_positions]\n",
    "            val_j = layer_j[violating_positions]\n",
    "            relative_errors = absolute_errors / (torch.max(val_i, val_j) + 1e-5)\n",
    "            total_relative_error = relative_errors.sum().item()\n",
    "            if violations_count > 1:\n",
    "                relative_error_std = relative_errors.std().item()\n",
    "\n",
    "        layer_stats = LayerStats(\n",
    "            combinations=total_combinations,\n",
    "            violations_count=violations_count,\n",
    "            total_absolute_error=total_absolute_error,\n",
    "            total_relative_error=total_relative_error,\n",
    "            violation_rate=violations_count / max(total_combinations, 1),\n",
    "            absolute_error=total_absolute_error / max(violations_count, 1),\n",
    "            absolute_error_std=absolute_error_std,\n",
    "            relative_error=total_relative_error / max(violations_count, 1),\n",
    "            relative_error_std=relative_error_std,\n",
    "        )\n",
    "\n",
    "        all_layer_stats.append(layer_stats)\n",
    "\n",
    "    return all_layer_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee82354",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_models_stats = {}\n",
    "for model_name in model_names:\n",
    "    print(f\"Processing model: {model_name}\")\n",
    "    mean_attention_matrix = load_attention_matrix(model_name)\n",
    "    softmax_mean_attention_matrix = compute_softmax_attention(mean_attention_matrix)\n",
    "    all_layer_stats = compute_monotonicity_stats(softmax_mean_attention_matrix)\n",
    "    all_models_stats[model_name] = all_layer_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0fe4c24",
   "metadata": {},
   "outputs": [],
   "source": [
    "formatted_model_name = {\n",
    "    \"anas-awadalla_mpt-7b\": \"mpt-7b\",\n",
    "    \"bigscience_bloom\": \"bloom-176b\",\n",
    "    \"bigscience_bloom-7b1\": \"bloom-7b\",\n",
    "    \"tiiuae_falcon-rw-7b\": \"falcon-rw-7b\",\n",
    "    \"eluzhnica_mpt-30b-peft-compatible\": \"mpt-30b\",\n",
    "}\n",
    "\n",
    "\n",
    "def style_attn_plot(ax: Axes, ylabel: str) -> None:\n",
    "    \"\"\"Style attention plot axes.\"\"\"\n",
    "    plt.style.use([\"science\", \"bright\", \"grid\", \"no-latex\"])\n",
    "    # Use sans-serif fonts (incl. mathtext) for cleaner small-scale rendering.\n",
    "    plt.rcParams.update(\n",
    "        {\n",
    "            \"font.family\": \"sans-serif\",\n",
    "            \"font.sans-serif\": [\"DejaVu Sans\", \"Liberation Sans\", \"Arial\"],\n",
    "            \"mathtext.fontset\": \"dejavusans\",\n",
    "        },\n",
    "    )\n",
    "    ax.set_xlabel(\"Layer\", fontsize=10)\n",
    "    ax.set_ylabel(ylabel, fontsize=10)\n",
    "    ax.tick_params(axis=\"both\", which=\"major\", labelsize=9)\n",
    "    ax.legend(fontsize=9, frameon=False, handlelength=1.2, columnspacing=0.8)\n",
    "    ax.margins(x=0.02)\n",
    "    ax.grid(visible=True, which=\"major\", alpha=0.2)\n",
    "\n",
    "\n",
    "def save_figure(fig: plt.Figure, filename: str) -> None:\n",
    "    \"\"\"Save figure to current folder as PDF.\"\"\"\n",
    "    fig.savefig(\n",
    "        result_dir / filename,\n",
    "        format=\"pdf\",\n",
    "        dpi=400,\n",
    "        bbox_inches=\"tight\",\n",
    "    )\n",
    "    print(f\"Figure saved to {result_dir / filename}\")\n",
    "\n",
    "\n",
    "def plot_layer_stats(all_models_stats: dict[str, list[LayerStats]]) -> None:\n",
    "    \"\"\"Plot monotonicity violation statistics across layers for all models.\"\"\"\n",
    "    # Violation Rate\n",
    "    fig, ax = plt.subplots(figsize=(4.5, 3), dpi=400)\n",
    "    for model_name, stats_list in all_models_stats.items():\n",
    "        violation_rates = np.array([stats.violation_rate for stats in stats_list])\n",
    "        layers = np.arange(1, len(stats_list) + 1)\n",
    "        ax.plot(\n",
    "            layers,\n",
    "            violation_rates,\n",
    "            label=formatted_model_name[model_name],\n",
    "            linewidth=1.5,\n",
    "        )\n",
    "\n",
    "    style_attn_plot(ax, \"Violation Rate\")\n",
    "    fig.tight_layout()\n",
    "    save_figure(fig, \"violation_rate.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "    # Average Absolute Error\n",
    "    fig, ax = plt.subplots(figsize=(4.5, 3), dpi=400)\n",
    "    for model_name, stats_list in all_models_stats.items():\n",
    "        absolute_errors = np.array([stats.absolute_error for stats in stats_list])\n",
    "\n",
    "        layers = np.arange(1, len(stats_list) + 1)\n",
    "\n",
    "        ax.plot(\n",
    "            layers,\n",
    "            absolute_errors,\n",
    "            label=formatted_model_name[model_name],\n",
    "            linewidth=1.5,\n",
    "        )\n",
    "\n",
    "        if show_std_error:\n",
    "            absolute_errors_std = np.array(\n",
    "                [stats.absolute_error_std for stats in stats_list],\n",
    "            )\n",
    "            ci = 2 * absolute_errors_std\n",
    "            ax.fill_between(\n",
    "                layers,\n",
    "                absolute_errors - ci,\n",
    "                absolute_errors + ci,\n",
    "                alpha=0.2,\n",
    "                linewidth=0,\n",
    "            )\n",
    "\n",
    "    style_attn_plot(ax, \"Average Absolute Error\")\n",
    "    fig.tight_layout()\n",
    "    save_figure(fig, \"average_absolute_error.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "    # Average Relative Error\n",
    "    fig, ax = plt.subplots(figsize=(4.5, 3), dpi=400)\n",
    "    for model_name, stats_list in all_models_stats.items():\n",
    "        relative_errors = np.array([stats.relative_error for stats in stats_list])\n",
    "\n",
    "        layers = np.arange(1, len(stats_list) + 1)\n",
    "        ax.plot(\n",
    "            layers,\n",
    "            relative_errors,\n",
    "            label=formatted_model_name[model_name],\n",
    "            linewidth=1.5,\n",
    "        )\n",
    "\n",
    "        if show_std_error:\n",
    "            relative_errors_std = np.array(\n",
    "                [stats.relative_error_std for stats in stats_list],\n",
    "            )\n",
    "            ci = 2 * relative_errors_std\n",
    "            ax.fill_between(\n",
    "                layers,\n",
    "                relative_errors - ci,\n",
    "                relative_errors + ci,\n",
    "                alpha=0.2,\n",
    "                linewidth=0,\n",
    "            )\n",
    "\n",
    "    style_attn_plot(ax, \"Average Relative Error\")\n",
    "    fig.tight_layout()\n",
    "    save_figure(fig, \"average_relative_error.pdf\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "plot_layer_stats(all_models_stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "position-bias",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
