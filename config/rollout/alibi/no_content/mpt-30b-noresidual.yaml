
sequence_length: 256
num_layers: 48

mask_config:
  mask_type: "causal"
  window_size: null
attention_config:
  num_heads: 64
  alibi_slopes: [[0.9170040432046712, 0.8408964152537145, 0.7711054127039704, 0.7071067811865476, 0.6484197773255048, 0.5946035575013605, 0.5452538663326288, 0.5, 0.4585020216023356, 0.42044820762685725, 0.3855527063519852, 0.3535533905932738, 0.3242098886627524, 0.29730177875068026, 0.2726269331663144, 0.25, 0.2292510108011678, 0.21022410381342863, 0.1927763531759926, 0.1767766952966369, 0.1621049443313762, 0.14865088937534013, 0.1363134665831572, 0.125, 0.1146255054005839, 0.10511205190671431, 0.0963881765879963, 0.08838834764831845, 0.0810524721656881, 0.07432544468767006, 0.0681567332915786, 0.0625, 0.05731275270029195, 0.052556025953357156, 0.04819408829399815, 0.04419417382415922, 0.04052623608284405, 0.03716272234383503, 0.0340783666457893, 0.03125, 0.028656376350145975, 0.026278012976678578, 0.024097044146999074, 0.02209708691207961, 0.020263118041422026, 0.018581361171917516, 0.01703918332289465, 0.015625, 0.014328188175072988, 0.013139006488339289, 0.012048522073499537, 0.011048543456039806, 0.010131559020711013, 0.009290680585958758, 0.008519591661447326, 0.0078125, 0.007164094087536494, 0.0065695032441696445, 0.0060242610367497685, 0.005524271728019903, 0.005065779510355506, 0.004645340292979379, 0.004259795830723663, 0.00390625]]
  head_weights: null
  softmax_temperature: 1.0
content_config:
  diagonal_scores: [[0.0]]
  base_scores: [[0.0]]
lambda_schedule_config:
  schedule_type: "constant"
  lambda_const: 1.0

save_dir: ./results/rollout/no_content/mpt-30b-noresidual/
