sequence_length: 256
num_layers: 32

mask_config:
  mask_type: "causal"
  window_size: null
attention_config:
  num_heads: 32
  alibi_slopes: [[0.8408964152537145, 0.7071067811865476, 0.5946035575013605, 0.5, 0.42044820762685725, 0.3535533905932738, 0.29730177875068026, 0.25, 0.21022410381342863, 0.1767766952966369, 0.14865088937534013, 0.125, 0.10511205190671431, 0.08838834764831845, 0.07432544468767006, 0.0625, 0.052556025953357156, 0.04419417382415922, 0.03716272234383503, 0.03125, 0.026278012976678578, 0.02209708691207961, 0.018581361171917516, 0.015625, 0.013139006488339289, 0.011048543456039806, 0.009290680585958758, 0.0078125, 0.0065695032441696445, 0.005524271728019903, 0.004645340292979379, 0.00390625]]
  head_weights: null
  softmax_temperature: 1.0
content_config:
  diagonal_scores: [[0.0]]
  base_scores: [[0.0]]
lambda_schedule_config:
  schedule_type: "constant"
  lambda_const: 1.0

save_dir: ./results/rollout/no_content/mpt-7b-noresidual/
